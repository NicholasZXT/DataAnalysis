{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02b1349-1669-4287-861c-b8c5c0e4dfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package版本信息：\n",
      "numpy:       1.22.3\n",
      "pandas:      1.4.2\n",
      "matplotlib:  3.5.1\n",
      "sklearn:     1.0.2\n",
      "seaborn:     0.11.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import plotly.express as px\n",
    "# from plotly import graph_objects as go\n",
    "\n",
    "import matplotlib\n",
    "# import plotly\n",
    "import sklearn\n",
    "\n",
    "print(\"package版本信息：\")\n",
    "print(\"numpy:      \", np.__version__)\n",
    "print(\"pandas:     \", pd.__version__)\n",
    "print(\"matplotlib: \", matplotlib.__version__)\n",
    "print(\"sklearn:    \", sklearn.__version__)\n",
    "print(\"seaborn:    \", sns.__version__)\n",
    "# print(\"plotly:     \", plotly.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a545c19-1843-48e6-8f98-0abb64a01131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置显示所有的列\n",
    "pd.options.display.max_columns = None\n",
    "# 设置显示所有的行\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "# 阻止waring显示\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# jupyter notebook设置同一个cell打印多个结果\n",
    "from IPython.display import display\n",
    "# 然后使用\n",
    "# display(\"a\")\n",
    "# display(\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de91182f-4fe3-422a-89f9-3c46c297b722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/danielzhang/Documents/Python-Projects/DataAnalysis\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34cbc817-e32c-49ce-9c19-9d8ec5bc9876",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/danielzhang/Documents/Python-Projects/DataAnalysis'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c83bdd-fc10-4b40-af0b-2b60b5ec30c0",
   "metadata": {},
   "source": [
    "主要讨论使用sklearn构建机器学习的流水线，实现一步到位的处理过程。\n",
    "\n",
    "参考文档：\n",
    "+ [sklearn -> 6.1. Pipelines and composite estimators](https://scikit-learn.org/stable/modules/compose.html#pipelines-and-composite-estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa98add3-ab37-4fce-a866-509cd657c789",
   "metadata": {},
   "source": [
    "# 流水线\n",
    "\n",
    "sklearn中流水线功能主要由 `sklearn.pipeline` 这个模块提供，主要是如下的`Pipeline`类\n",
    "\n",
    "`Pipeline(steps, *, memory=None, verbose=False)`类\n",
    "+ 主要参数\n",
    "  + `steps`：list of (name, transformer) tuples，其中每个transformer都必须实现`fit`/`transform`方法，最后一个必须是estimator\n",
    "\n",
    "此外，还有一个`make_pipeline()`函数，用于快速创建一个`Pipeline`对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f1522a-2fa3-4aef-b1ed-05190cfb0c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d9b0f59-64a2-48f9-b942-13822c155073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('reduce_dim', PCA()), ('clf', SVC())])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators = [('reduce_dim', PCA()), ('clf', SVC())]\n",
    "pipe = Pipeline(estimators)\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a415c0d-13b1-4c94-82f1-fcfa45b62368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pca', PCA()), ('svc', SVC())])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 或者使用 make_pipeline，会自动生成每个步骤的名字\n",
    "pipe2 = make_pipeline(PCA(), SVC())\n",
    "pipe2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a524061-4014-461d-9f6a-d2cc574dac30",
   "metadata": {},
   "source": [
    "# 多类型数据转换\n",
    "\n",
    "通常数据的特征会有多种类型，比如同时含有类别型和数值型特征，此时在pipeline中添加数据预处理步骤时，需要对不同的特征使用不同的变换器，比如对于类别型使用one-hot编码，对于计数型特征使用分箱KBinarize。  \n",
    "\n",
    "此时就需要`sklearn.compose`模块中的`ColumnTransformer`类的协助：   \n",
    "\n",
    "`ColumnTransformer(transformers, *, remainder='drop', sparse_threshold=0.3, n_jobs=None, transformer_weights=None, verbose=False, verbose_feature_names_out=True)`\n",
    "+ `transformers`：   \n",
    "  List of (name, transformer, columns) tuples，用于指定各个列的转换器\n",
    "  + name：str，转换器的名称\n",
    "  + transformer：estimator对象 或者 {‘drop’, ‘passthrough’}，estimator时使用对应的转换器，'drop'表示该列特征被丢弃，'passthrough'表示该列不做任何处理\n",
    "  + columns：指定该转换器对应的列，str, array-like of str 时指定列名称，int, array-like of int时指定列的索引\n",
    "+ `remainder`：指定剩余列如何处理\n",
    "  + 'drop'，丢弃剩余列，这是**默认值**\n",
    "  + 'passthrough'，不做任何处理\n",
    "  + estimator，使用指定的估计器处理剩余列\n",
    "  \n",
    "此外，还有一个`make_column_transformer()`函数，用于快速创建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee6a81e1-f590-4eef-a04a-be0030a7f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67fd5266-d930-44ce-83df-38af06489e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1  col2  col3\n",
       "0    a     1     6\n",
       "1    b     5     7\n",
       "2    a     2     8\n",
       "3    b     3     9\n",
       "4    a     4    10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'col1': ['a', 'b', 'a', 'b', 'a'],\n",
    "    'col2': [1, 5, 2, 3, 4],\n",
    "    'col3': [6, 7, 8, 9, 10]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f76705c1-1973-4134-8101-0718ed8a9e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers=[('one-hot', OneHotEncoder(), ['col1']), ('min-max', MinMaxScaler(), ['col2'])]\n",
    "ctf = ColumnTransformer(transformers=transformers, remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11b89b52-eab0-4c38-af9f-46a22332abb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('one-hot', OneHotEncoder(), ['col1']),\n",
       "                                ('min-max', MinMaxScaler(), ['col2'])])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "858e98cd-dce0-48d5-bdfe-0ad7af7b50b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('one-hot', OneHotEncoder(), ['col1']), ('min-max', MinMaxScaler(), ['col2'])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf.transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17230486-08d0-4116-99a7-8616822f8c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 1.  ],\n",
       "       [1.  , 0.  , 0.25],\n",
       "       [0.  , 1.  , 0.5 ],\n",
       "       [1.  , 0.  , 0.75]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# col1 列使用 one-hot编码，产生2个特征，col2列只是缩放，仍然输出一个特征，col3没有指定转换器，处理方式为drop，所以最后的输出中被丢弃了\n",
    "# 所以最后输出 3 列\n",
    "ctf.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1fe64f8-9c6f-4341-9485-53a75f5f0970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  0.  ,  0.  ,  6.  ],\n",
       "       [ 0.  ,  1.  ,  1.  ,  7.  ],\n",
       "       [ 1.  ,  0.  ,  0.25,  8.  ],\n",
       "       [ 0.  ,  1.  ,  0.5 ,  9.  ],\n",
       "       [ 1.  ,  0.  ,  0.75, 10.  ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# col1 列使用 one-hot编码，产生2个特征，col2列只是缩放，仍然输出一个特征，col3没有指定转换器，处理方式为passthrough，所以最后的输出保持不变\n",
    "# 所以最后输出 4 列\n",
    "ctf = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "ctf.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd0754a-dbbd-4145-be28-89a5b79cb2d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 封装自定义转换\n",
    "\n",
    "如果要实现自定义转换，则需要使用`sklearn.preprocess`包中的`FunctionTransformer`类，对自定义处理流程进行包装。\n",
    "\n",
    "`FunctionTransformer(func=None, inverse_func=None, *, validate=False, accept_sparse=False, check_inverse=True, feature_names_out=None, kw_args=None, inv_kw_args=None)`\n",
    "+ `func`，自定义的处理流程函数\n",
    "+ `inverse_func`，逆变换函数，可以为None，此时逆变换为等值变换\n",
    "+ `kw_args`，dict, default=None，传递给自定义`func`的参数\n",
    "\n",
    "注意，**这样封装的变换一般是stateless的，比如单纯的对数转换之类的，不需要保存状态**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4000e3ec-6156-4dcc-847d-a529469c0020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5061fac2-0d48-4466-945e-42e8814a328c",
   "metadata": {},
   "source": [
    "# 实现自定义转换器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d394aedc-f714-4d7b-9aea-2d34b94f5223",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 特征融合\n",
    "\n",
    "对同一组特征 **并行** 使用 $N$ 个转换器，然后将得到的 $N$ 个输出拼接成新的特征。  \n",
    "\n",
    "使用`sklearn.pipeline`模块中的`FeatureUnion`类：   \n",
    "`FeatureUnion(transformer_list, *, n_jobs=None, transformer_weights=None, verbose=False)`\n",
    "+ `transformer_list`：list of (str, transformer) tuples，指定转换器，之后这些转换器的输出会被拼接起来。\n",
    "\n",
    "还有一个`make_union()`函数方便使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea7f034a-575e-4adf-8380-434561c67a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import PCA, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c85d97ec-3c4d-40bc-90bc-9dcc77293bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(transformer_list=[('pca', PCA(n_components=2)),\n",
       "                               ('svd', TruncatedSVD())])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[0., 1., 3], [2., 2., 5]]\n",
    "\n",
    "# PCA 保留2个特征， SVD 保留2个特征，最终的输出是 2+2=4 个特征\n",
    "union = FeatureUnion([(\"pca\", PCA(n_components=2)), (\"svd\", TruncatedSVD(n_components=2))])\n",
    "union.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35e7d9f4-7b98-4b3e-8939-9f91f36134f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.50000000e+00, -1.11022302e-16,  3.03954967e+00,\n",
       "         8.72432133e-01],\n",
       "       [-1.50000000e+00,  1.11022302e-16,  5.72586357e+00,\n",
       "        -4.63126787e-01]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c74ddf-f177-4ea6-a995-07e5bb11d179",
   "metadata": {},
   "source": [
    "# 目标特征转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e2da50-95e9-4e48-83df-9062834fcf4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis(Python3.8.12)",
   "language": "python",
   "name": "data-analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
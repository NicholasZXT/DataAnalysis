{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package版本信息：\n",
      "numpy:       1.19.2\n",
      "pandas:      1.0.1\n",
      "matplotlib:  3.3.1\n",
      "sklearn:     0.23.2\n",
      "seaborn:     0.11.1\n",
      "plotly:      4.14.1\n",
      "PyTorch:      1.2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from plotly import graph_objects as go\n",
    "\n",
    "import matplotlib\n",
    "import plotly\n",
    "import sklearn\n",
    "import torch\n",
    "\n",
    "from IPython.display import display\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "print(\"package版本信息：\")\n",
    "print(\"numpy:      \", np.__version__)\n",
    "print(\"pandas:     \", pd.__version__)\n",
    "print(\"matplotlib: \", matplotlib.__version__)\n",
    "print(\"sklearn:    \", sklearn.__version__)\n",
    "print(\"seaborn:    \", sns.__version__)\n",
    "print(\"plotly:     \", plotly.__version__)\n",
    "print(\"PyTorch:     \", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor基础\n",
    "\n",
    "PyTorch的设计遵循着 **Tensor(高维数组) ——> Varible(自动求导AutoGrad) ——> nn.Module(神经网络层/模块)** 三个由低到高的抽象层次."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建Tensor\n",
    "\n",
    "有两种方式可以创建Tensor：\n",
    "1. 使用`torch.Tensor()`构造方法，注意，这是`torch.Tensor`类的构造器方法\n",
    "2. 使用`torch.xxx()`函数来创建Tensor，比如：\n",
    "  + `torch.tensor(data, dtype=None, device=None, requires_grad=False,)`——这是静态函数，用于从已有数据中创建tensor，注意这里的`requires_grad`参数。\n",
    "  + `torch.ones()`\n",
    "  + `torch.zeros()`\n",
    "  \n",
    "上述两种方法都会返回`torch.Tensor`的对象。\n",
    "\n",
    "有关`torch.Tensor()`方法和`torch.tensor()`方法的讨论见问答 [What is the difference between torch.tensor and torch.Tensor?](https://stackoverflow.com/questions/51911749/what-is-the-difference-between-torch-tensor-and-torch-tensor).\n",
    "\n",
    "+ 基本创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.9339e+32, 7.5551e+31, 1.5089e-19],\n",
       "        [4.4656e+30, 3.3917e-15, 0.0000e+00]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用构造方法，指定tensor的shape\n",
    "t1 = torch.Tensor(2,3)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用构造方法，从 list of list 中创建\n",
    "t2 = torch.Tensor([[1,2,3], [4,5,6]])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用静态方法\n",
    "t3 = torch.tensor([[1,2]])\n",
    "t3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Tensor的一些属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 常用的创建方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全 1 Tensor\n",
    "torch.ones(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全 0 \n",
    "torch.zeros(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 步长\n",
    "torch.arange(1, 6, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  5.5000, 10.0000])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(1, 10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4395, 0.3174, 0.5914],\n",
       "        [0.2081, 0.3722, 0.5950],\n",
       "        [0.5110, 0.2151, 0.0040],\n",
       "        [0.8960, 0.6777, 0.7021],\n",
       "        [0.1643, 0.4797, 0.0276]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 均匀分布随机数\n",
    "torch.rand(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8362, -0.4455, -0.4478,  1.5865],\n",
       "        [ 1.1634,  1.4463,  0.3926,  0.1785],\n",
       "        [-0.8441, -1.5769, -0.8146,  0.8134]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正态随机数\n",
    "torch.randn(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对角线为1\n",
    "torch.eye(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor类型\n",
    "\n",
    "Tensor有各种类型，并且每种类型有CPU和GPU版本。\n",
    "\n",
    "类型之间的转换有三种方式，设已有tensor `a` 和 `b`\n",
    "1. `a.type(torch.FloatTensor)`，\n",
    "2. `a.float()`，便捷的方式\n",
    "3. `a.as_type(b)`，使用`b`的类型来设置`a`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2])\n",
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.type(torch.FloatTensor)\n",
    "c.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.float()\n",
    "c.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 操作Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd\n",
    "\n",
    "`torch.autograd` 模块是一套专门用于自动求导的引擎，能够根据输入和前向传播过程自动**动态地**构建计算图，并执行反向传播。\n",
    "\n",
    "Autograd 模块中的核心数据结构是`Variable`，它是对Tensor的封装，同时记录了对Tensor的操作，用于构建计算图。  \n",
    "`Variable`包含三个属性：\n",
    "+ `data`：保存`Variable`包含的Tensor\n",
    "+ `grad`：保存`data`对应的梯度，它本身也是一个`Variable`，与`data`形状一致\n",
    "+ `grad_fn`：指向一个Function，记录`Variable`的操作历史，用于构建计算图。对于叶子节点，它指向的None。\n",
    "\n",
    "注意:\n",
    "> 从 **0.4 版本**开始，`torch.Tensor`和`torch.autograd.Variable`被合并到了一起。  \n",
    "更确切地说，`torch.Tensor`能够像旧版`Variable`一样追踪历史，`Variable`封装还像过去那样工作，但返回一个`torch.Tensor`类型的对象。  \n",
    "这意味着不再需要在代码中到处使用`Variable`封装器。\n",
    "\n",
    "创建Tensor的时候，有两种方式让这个Tensor作为变量进行求导操作：\n",
    "1. 创建时指定参数`required_grad=True`\n",
    "2. 创建后通过`torch.Tensor`对象的`.required_grad`属性进行设置\n",
    "\n",
    "注意，**只有浮点数类的Tensor才能设置求导**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2.],\n",
       "        [2., 2., 2.]], requires_grad=True)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下面可以看出，Variable已经和Tensor合并了\n",
    "from torch.autograd import Variable\n",
    "a = Variable(torch.ones(2,3)*2, requires_grad=True)\n",
    "print(a.__class__)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多元函数的反向求导\n",
    "\n",
    "多元函数是 $R^n \\Rightarrow R$ 的一个映射：自变量 $x \\in R^n$，因变量 $y=f(x) \\in R$. 这种情况下，偏导数 $\\frac{\\partial f}{\\partial x} \\in R^n$ 也是一个 $n$ 维向量.  \n",
    "\n",
    "这里构造一个 $c = 3 \\times a^2 + b^2$ 的例子，这个计算中，可以进一步拆成如下的简单四则运算的节点：\n",
    "1. 节点 $a$ 和 $b$ 都是输入节点——也被称为计算图的**叶子节点**\n",
    "2. 中间节点 $t_1 = a^2$，$t_2 = b^2$ 和 $t_3 = 3 \\times t_1$ —— 对应于计算图的**非叶子节点**\n",
    "3. 最终的节点 $c = t_3 + t_2$。\n",
    "\n",
    "下面的代码中，为了简便起见，将 $t_1$ 和 $t_3$ 合并为一个 $t_1 = 3 \\times a^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.requires_grad:  True\n",
      "a.grad:  None\n",
      "a.grad_fn:  None\n",
      "b.requires_grad:  True\n",
      "b.grad:  None\n",
      "b.grad_fn:  None\n"
     ]
    }
   ],
   "source": [
    "# 注意，这里只能使用 tensor 静态方法，不能使用 torch.Tensor() 构造方法\n",
    "# 这里必须是 浮点数 1.0，不能是 整数 1\n",
    "a = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "# 第二种方式指定求导\n",
    "b = torch.tensor([1.0])\n",
    "b.requires_grad=True\n",
    "\n",
    "print(\"a.requires_grad: \",a.requires_grad)\n",
    "print(\"a.grad: \", a.grad)\n",
    "print(\"a.grad_fn: \", a.grad_fn)  # 由于 `a` 是手动创建的，所以它的 `grad_fn` 为 None\n",
    "print(\"b.requires_grad: \",b.requires_grad)\n",
    "print(\"b.grad: \", b.grad)\n",
    "print(\"b.grad_fn: \", b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------检查各节点的梯度-------------------\n",
      "t1.requires_grad:  True\n",
      "t1.grad:  None\n",
      "t1.grad_fn:  <MulBackward0 object at 0x0000022724238BE0>\n",
      "t2.requires_grad:  True\n",
      "t2.grad:  None\n",
      "t2.grad_fn:  <PowBackward0 object at 0x000002272D296CC0>\n",
      "c.requires_grad:  True\n",
      "c.grad:  None\n",
      "c.grad_fn:  <AddBackward0 object at 0x000002272D2960B8>\n",
      "-----------检查是否为叶子节点----------------\n",
      "a.is_leaf: True\n",
      "b.is_leaf: True\n",
      "t1.is_leaf: False\n",
      "t2.is_leaf: False\n",
      "c.is_leaf: False\n"
     ]
    }
   ],
   "source": [
    "# 下面的 t1，t2 是显式表示出来的非叶子节点\n",
    "t1 = 3*a**2\n",
    "t2 = b**2\n",
    "c = t1 + t2\n",
    "\n",
    "print(\"-----------检查各节点的梯度-------------------\")\n",
    "print(\"t1.requires_grad: \",t1.requires_grad)\n",
    "print(\"t1.grad: \", t1.grad)\n",
    "print(\"t1.grad_fn: \",t1.grad_fn)  # t1 是经过计算的（乘法），所以有梯度函数\n",
    "\n",
    "print(\"t2.requires_grad: \",t2.requires_grad)\n",
    "print(\"t2.grad: \", t2.grad)\n",
    "print(\"t2.grad_fn: \",t2.grad_fn)  # t2 是经过计算的（求幂），所以有梯度函数\n",
    "\n",
    "print(\"c.requires_grad: \",c.requires_grad)\n",
    "print(\"c.grad: \", c.grad)\n",
    "print(\"c.grad_fn: \",c.grad_fn)  # c 是经过计算的（加法），所以有梯度函数\n",
    "\n",
    "# 检查节点是否为叶子节点\n",
    "print(\"-----------检查是否为叶子节点----------------\")\n",
    "print(\"a.is_leaf:\", a.is_leaf)\n",
    "print(\"b.is_leaf:\", b.is_leaf)\n",
    "print(\"t1.is_leaf:\", t1.is_leaf)\n",
    "print(\"t2.is_leaf:\", t2.is_leaf)\n",
    "print(\"c.is_leaf:\", c.is_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面所有tensor的梯度`.grad`都是None，因为还没有执行过反向求导计算。    \n",
    "其中 `a` 和 `b` 是**叶子节点**，叶子节点是计算图的起点，所以对应的 `.grad_fn` 总是 None；   \n",
    "`t1` 代表的 $3\\times a^2$ 和 `t2` 代表的 $b^2$ 是**非叶子节点，非叶子节点总是由叶子节点经过层层运算得到**，所以它们的 `.grad_fn` 是对应的上一层的转化操作。\n",
    "\n",
    "下面从 `c` 所在的节点 关于两个叶子节点 `a` 和 `b` 执行反向求导计算 。  \n",
    "$\\frac{\\partial c}{\\partial a} = 6a$,   $\\frac{\\partial c}{\\partial b} = 2b$.  \n",
    "由于tensor `a`=1， `b`=1，代入上述的梯度，就得到 `a.grad`=6, `b.grad`=2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.grad:  tensor([6.], grad_fn=<CloneBackward>)\n",
      "b.grad:  tensor([2.], grad_fn=<CloneBackward>)\n",
      "t1.grad:  None\n",
      "t2.grad:  None\n",
      "c.grad:  None\n"
     ]
    }
   ],
   "source": [
    "# 在 c 节点执行反向求导计算\n",
    "# 如果想再次执行下面的 .backward()，在没有设置参数 retain_graph=True ，只能重新构建一次计算图\n",
    "# 重新构建计算图有两种方式：\n",
    "# 第一种：重新赋值，\n",
    "# c = t1 + t2\n",
    "# c.backward()\n",
    "# 另一种是 设置 create_grap=True\n",
    "c.backward(create_graph=True)\n",
    "\n",
    "# 设置参数 retain_graph=True，可以多次执行梯度计算，不过这种情况下，叶子节点的梯度就是逐次累加的\n",
    "# c.backward(retain_graph=True)\n",
    "\n",
    "print(\"a.grad: \", a.grad)\n",
    "print(\"b.grad: \", b.grad)\n",
    "print(\"t1.grad: \", t1.grad)\n",
    "print(\"t2.grad: \", t2.grad)\n",
    "print(\"c.grad: \", c.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认下，执行`.backward()`方法会构建从叶子节点到 `c` 节点的计算图，然后反向每个计算节点的梯度。  \n",
    "默认情况下，为了减少内存占用，**只有叶子节点的梯度会被保留，非叶子节点的梯度在计算完叶子节点的梯度后，会被删除** 。  \n",
    "**如果想保留计算图中非叶子节点的梯度，需要设置`.backward()`中的参数`retain_graph=True`** 。  \n",
    "参数`retain_graph=True`时，多次执行`.backward()`函数，**叶子节点的梯度是会累加的**。\n",
    "\n",
    "上面的`c.backward()`只能执行一次，如果再次执行，就会报错，就是因为计算图中非叶子节点的梯度已经被删除了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量函数的反向求导\n",
    "\n",
    "另一种情况是向量函数的偏导数.  \n",
    "所谓**向量函数**，是 $ R^n \\Rightarrow R^m$ 的一个映射：自变量 $x \\in R^n $ 是一个 $n$ 维向量，同时因变量 $f(x) = (y_1, y_2,..., y_m)^T \\in R^m$ 也是一个 $m$ 维向量，其中的 $y_j = y_j(x) \\in R$ 是一个多元函数。 \n",
    "\n",
    "PyTorch的`autograd`模块有个简单粗暴的规定，**只能执行标量对张量的求导，不能执行张量对张量的求导** 。  \n",
    "为了对向量函数求偏导数，也就是实现张量对张量的求导，PyTorch的`.backward()`方法里，提供了一个 `grad_variables=` 参数，它是一个 $m$ 维的向量，维度和 $f(x)$ 一样，作用是和 $f(x)$ 做内积，得到一个实数，然后对这个实数变量求偏导数.  \n",
    "具体来说，就是设 `grad_variables`参数对应的向量是 $v \\in R^m$，那么就会得到一个内积值 $l = \\sum_{j=1}^{m}{v_j y_j(x)} \\in R$，那么就是：  \n",
    "$\\frac{\\partial l}{\\partial x} = \\frac{\\partial l}{\\partial y}\\frac{\\partial y}{\\partial x}$，其中 $\\frac{\\partial l}{\\partial y} = v \\in R^m$，而 $\\frac{\\partial y}{\\partial x} \\in R^{m\\times n}$ 是一个雅克比矩阵，两者相乘，最后得到的就是一个 $n$ 维的梯度向量.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的例子中, $x \\in R^2$, $y = (x+1)^2+3 \\in R^2$ 表示对应的分量执行相同的运算，这里相当于 $f(x) \\in R^2$，并且  \n",
    "$\n",
    "\\left\\{\n",
    "\\begin{array}\\\n",
    "y_1(x) = y_1(x_1) = (x_1+1)^2+3 \\\\\n",
    "y_2(x) = y_2(x_2) = (x_2+1)^2+3\n",
    "\\end{array}\n",
    "\\right.\n",
    "$,\n",
    "\n",
    "$\n",
    "\\frac{\\partial y}{\\partial x} =\n",
    "\\left\\{\n",
    "\\begin{matrix}\n",
    "   \\frac{\\partial y_1}{\\partial x_1} & \\frac{\\partial y_1}{\\partial x_2} \\\\\n",
    "   \\frac{\\partial y_2}{\\partial x_1} & \\frac{\\partial y_2}{\\partial x_2} \n",
    "\\end{matrix}\n",
    "\\right\\}\n",
    "=\n",
    "\\left\\{\n",
    "\\begin{matrix}\n",
    "   2(x_1+1) & 0 \\\\\n",
    "   0 & 2(x_2+1) \n",
    "\\end{matrix}\n",
    "\\right\\}\n",
    "$.\n",
    "\n",
    "当 $x=[1, 2]^T$ 时，\n",
    "$\n",
    "\\frac{\\partial y}{\\partial x} =\n",
    "\\left\\{\n",
    "\\begin{matrix}\n",
    "   4 & 0 \\\\\n",
    "   0 & 6 \n",
    "\\end{matrix}\n",
    "\\right\\}\n",
    "$.\n",
    "\n",
    "当 `gradient` $=[1, 1]$时，\n",
    "$\n",
    "[1, 1]^T \\times\n",
    "\\left\\{\n",
    "\\begin{matrix}\n",
    "   4 & 0 \\\\\n",
    "   0 & 6 \n",
    "\\end{matrix}\n",
    "\\right\\}\n",
    "= [4, 6]^T\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([1., 2.], requires_grad=True)\n",
      "y: tensor([ 7., 12.], grad_fn=<AddBackward0>)\n",
      "x.grad:  tensor([4., 6.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y = (x+1)**2+3\n",
    "print(\"x:\", x)\n",
    "print(\"y:\", y)\n",
    "# y 是二维的值，直接调用 .backward() 会报错\n",
    "y.backward(gradient=torch.tensor([1.0, 1.0]))\n",
    "print(\"x.grad: \", x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当 `gradient` $=[1, 2]$时，\n",
    "$\n",
    "[1, 2]^T \\times\n",
    "\\left\\{\n",
    "\\begin{matrix}\n",
    "   4 & 0 \\\\\n",
    "   0 & 6 \n",
    "\\end{matrix}\n",
    "\\right\\}\n",
    "= [4, 12]^T\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad:  tensor([ 4., 12.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y = (x+1)**2+3\n",
    "# gradient = [1, 2]\n",
    "y.backward(gradient=torch.tensor([1.0, 2.0]))\n",
    "print(\"x.grad: \", x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad:  tensor([8., 6.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y = (x+1)**2+3\n",
    "# gradient = [2, 1]\n",
    "y.backward(gradient=torch.tensor([2.0, 1.0]))\n",
    "print(\"x.grad: \", x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义函数的反向求导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# 神经网络模块`nn.Module`\n",
    "\n",
    "使用PyTorch的`nn.Module`模块构建神经网络的过程如下图所示.\n",
    "\n",
    "<img src=\"images/pytorch-nn.module.png\" width=\"75%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建神经网络\n",
    "\n",
    "实际使用中，构建神经网络的最常见做法是继承 `nn.Module` 类，在其中定义自己的网络结构。\n",
    "\n",
    "`torch.nn`中的核心结构是`Module`，它是一个抽象的概念，既可以表示神经网络中的某个层，还可以表示包含很多层的神经网络。\n",
    "\n",
    "构建一个神经网络，有如下几步：\n",
    "1. 继承 `nn.Module` 抽象基类，\n",
    "2. 在初始化方法`__init__()`中，存放网络中可学习的参数\n",
    "3. 实现`nn.Module`抽象类中的前向传播方法`forward()`，梯度的反向传播方法不需要自己写，PyTorch会自动生成\n",
    "4. 网络的可学习参数可以通过网络实例对象的`.parameters()` 或者 `.named_parameters()` 返回"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数\n",
    "\n",
    "构建完神经网络的前向传播过程之后，需要计算神经网络输出的损失。\n",
    "\n",
    "PyTorch中，损失函数也位于 `nn.Module`这个模块中。\n",
    "\n",
    "损失函数有两种使用方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE\n",
    "`nn.MSELoss()`类，它实例化的对象接受的参数为`(Input, Target)`，`Input`和`Target`的shape必须是相同的，**可以是矩阵，此时计算的MSE就是矩阵对应元素之间的MSE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true:\n",
      "tensor([1., 2., 3.])\n",
      "y_pred:\n",
      "tensor([3., 4., 5.], requires_grad=True)\n",
      "MSE-Loss:\n",
      "tensor(4., grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# shape=(3,)\n",
    "y_true = torch.tensor([1,2,3], dtype=torch.float)\n",
    "y_pred = torch.tensor([3,4,5], dtype=torch.float, requires_grad=True)\n",
    "\n",
    "# shape=(3,1)\n",
    "# y_true = torch.tensor([[1], [2], [3]], dtype=torch.float)\n",
    "# y_pred = torch.tensor([[3], [4], [5]], dtype=torch.float, requires_grad=True)\n",
    "\n",
    "loss = mse(y_pred, y_true)\n",
    "\n",
    "print(\"y_true:\")\n",
    "print(y_true)\n",
    "print(\"y_pred:\")\n",
    "print(y_pred)\n",
    "\n",
    "print(\"MSE-Loss:\")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 下面这个矩阵计算的就是对应位置元素的MSE   \n",
    "$mse = (0+1+0+1+0+1)/6=\\frac{3}{6}=0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true:\n",
      "tensor([[1., 2.],\n",
      "        [2., 3.],\n",
      "        [3., 4.]])\n",
      "y_pred:\n",
      "tensor([[1., 3.],\n",
      "        [2., 4.],\n",
      "        [3., 5.]], requires_grad=True)\n",
      "MSE-Loss:\n",
      "tensor(0.5000, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "y_true = torch.tensor([[1,2], [2,3], [3,4]], dtype=torch.float)\n",
    "y_pred = torch.tensor([[1,3], [2,4], [3,5]], dtype=torch.float, requires_grad=True)\n",
    "# y_pred = torch.tensor([[1,4], [2,5], [3,6]], dtype=torch.float, requires_grad=True)\n",
    "\n",
    "loss = mse(y_pred, y_true)\n",
    "\n",
    "print(\"y_true:\")\n",
    "print(y_true)\n",
    "print(\"y_pred:\")\n",
    "print(y_pred)\n",
    "\n",
    "print(\"MSE-Loss:\")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对数似然误差\n",
    "\n",
    "对数似然误差(Negative Log Likelihood Loss, 缩写为**NLLL**)对应的类是 `nn.NLLLoss()`，可以用于多分类问题 .    \n",
    "它实例化的对象接受的参数为`(Input, Target)`：\n",
    "+ `Input`的 `shape=(batch_size, C)`，$C$ 是类别的个数\n",
    "+ `Target`的 `shape=(batch_size)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true.shape:  torch.Size([3])\n",
      "y_true:\n",
      "tensor([1, 0, 0])\n",
      "\n",
      "y_pred.shape:  torch.Size([3, 2])\n",
      "y_pred:\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], requires_grad=True)\n",
      "\n",
      "Negative-Likehood-Log-Loss:\n",
      "tensor(-0.3333, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "y_true = torch.tensor([1, 0, 0], dtype=torch.long)\n",
    "y_pred = torch.tensor([[1,0], [1,0], [0,1]], dtype=torch.float, requires_grad=True)\n",
    "\n",
    "print(\"y_true.shape: \", y_true.shape)\n",
    "print(\"y_true:\")\n",
    "print(y_true)\n",
    "print(\"\\ny_pred.shape: \", y_pred.shape)\n",
    "print(\"y_pred:\")\n",
    "print(y_pred)\n",
    "\n",
    "loss = nll(y_pred, y_true)\n",
    "\n",
    "print(\"\\nNegative-Likehood-Log-Loss:\")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交叉熵误差\n",
    "\n",
    "`nn.CrossEntropyLoss()`可以用于多分类问题 .    \n",
    "它实例化的对象接受的参数为`(Input, Target)`：\n",
    "+ `Input`的 `shape=(batch_size, C)`，$C$ 是类别的个数\n",
    "+ `Target`的 `shape=(batch_size)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossEnt = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true.shape:  torch.Size([3])\n",
      "y_true:\n",
      "tensor([1, 0, 0])\n",
      "\n",
      "y_pred.shape:  torch.Size([3, 2])\n",
      "y_pred:\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], requires_grad=True)\n",
      "\n",
      "Negative-Likehood-Log-Loss:\n",
      "tensor(0.9799, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "y_true = torch.tensor([1, 0, 0], dtype=torch.long)\n",
    "y_pred = torch.tensor([[1,0], [1,0], [0,1]], dtype=torch.float, requires_grad=True)\n",
    "\n",
    "print(\"y_true.shape: \", y_true.shape)\n",
    "print(\"y_true:\")\n",
    "print(y_true)\n",
    "print(\"\\ny_pred.shape: \", y_pred.shape)\n",
    "print(\"y_pred:\")\n",
    "print(y_pred)\n",
    "\n",
    "loss = crossEnt(y_pred, y_true)\n",
    "\n",
    "print(\"\\nNegative-Likehood-Log-Loss:\")\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器\n",
    "\n",
    "计算完神经网络前向传播的损失函数之后，需要使用PyTorch里的优化器模块 `torch.optim` 对损失函数进行反向求导，更新梯度.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作为示例，实现如下的一个简单神经网络，**它只有一个隐藏层，并且隐藏层没有使用激活函数。**\n",
    "\n",
    "<img src=\"images/f2.png\" width=\"70%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建网络的前向传播过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Perceptron(nn.Module):\n",
    "    \"\"\"\n",
    "    两层的感知机模型\n",
    "    \"\"\"\n",
    "    def __init__(self, dim_input, dim_hidden):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Parameter(torch.randn(dim_input, dim_hidden))\n",
    "        # 这里输出层本来应当是一个单元，但是作为分类问题，需要输出二分类下，各个类的概率，所以输出层也为2\n",
    "        self.w2 = nn.Parameter(torch.randn(dim_hidden, 2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        神经网络的前向传播函数\n",
    "        x: 输入的Tensor\n",
    "        \"\"\"\n",
    "        # print(\"x.shape: \", x.shape)\n",
    "        # print(\"w1.shape: \", self.w1.shape)\n",
    "        layer = x.mm(self.w1)\n",
    "        output = layer.mm(self.w2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模拟数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape:  (128, 2)\n",
      "X:\n",
      " [[0.86375999 0.28490597]\n",
      " [0.07325639 0.7632372 ]\n",
      " [0.45271906 0.54229687]\n",
      " [0.72663578 0.84890511]\n",
      " [0.76819998 0.73314372]]\n",
      "\n",
      "y_true.shape:  (128,)\n",
      "y_true:\n",
      " [0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 使用numpy随机模拟数据\n",
    "from numpy.random import RandomState\n",
    "\n",
    "rnd = RandomState(29)\n",
    "datasize = 128\n",
    "# 随机生成 datesize x 2 的矩阵\n",
    "X = rnd.rand(datasize,2)\n",
    "# 对于X中的每一行，计算一个对于的 y_true 值，\n",
    "# y_true = np.array([ [int(x1+x2<1)] for (x1,x2) in X])\n",
    "y_true = np.array([ int(x1+x2<1) for (x1,x2) in X])\n",
    "\n",
    "print(\"X.shape: \", X.shape)\n",
    "print(\"X:\\n\",X[:5,:])\n",
    "print(\"\\ny_true.shape: \", y_true.shape)\n",
    "print(\"y_true:\\n\",y_true[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter-w1 :\n",
      "Parameter containing:\n",
      "tensor([[ 1.1891,  0.3408, -0.3820],\n",
      "        [ 1.2111, -1.1438, -2.0302]], requires_grad=True)\n",
      "Parameter-w2 :\n",
      "Parameter containing:\n",
      "tensor([[ 1.7271, -1.0313],\n",
      "        [ 1.0159,  1.2647],\n",
      "        [-0.1260,  1.5183]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "percep = Perceptron(2, 3)\n",
    "# x = torch.tensor([1.0, 2.0]).reshape(1,2)\n",
    "# y  = percep.forward(x)\n",
    "# y\n",
    "\n",
    "for name, param in percep.named_parameters():\n",
    "    print(\"Parameter-{} :\\n{}\".format(name, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape:  torch.Size([128, 2])\n"
     ]
    }
   ],
   "source": [
    "y_pred = percep.forward(torch.tensor(X).type(torch.FloatTensor))\n",
    "print(\"y_pred.shape: \", y_pred.shape)\n",
    "# y_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropy-Loss:  tensor(1.8746, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "crossEnt = nn.CrossEntropyLoss()\n",
    "\n",
    "y_true_tensor = torch.tensor(y_true).type(torch.long)\n",
    "loss = criterion(y_pred, y_true_tensor)\n",
    "print(\"CrossEntropy-Loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用优化器更新梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter-w1 :\n",
      "Parameter containing:\n",
      "tensor([[ 0.7964,  0.3763, -0.1479],\n",
      "        [ 0.7198, -1.0995, -1.7373]], requires_grad=True)\n",
      "Parameter-w2 :\n",
      "Parameter containing:\n",
      "tensor([[ 1.3422, -0.6463],\n",
      "        [ 1.1711,  1.1095],\n",
      "        [ 0.2900,  1.1023]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 1. 优化器，传入已有神经网络对象的参数\n",
    "sgd = optim.SGD(params=percep.parameters(), lr=1)\n",
    "\n",
    "# 2. 清空梯度\n",
    "sgd.zero_grad()\n",
    "\n",
    "# 3. 对损失函数进行反向求导\n",
    "loss.backward()\n",
    "\n",
    "# 4. 执行优化器，更新梯度\n",
    "sgd.step()\n",
    "\n",
    "# 5. 检查更新后的梯度参数\n",
    "for name, param in percep.named_parameters():\n",
    "    print(\"Parameter-{} :\\n{}\".format(name, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropy-Loss:  tensor(0.9022, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 检查新的交叉熵损失\n",
    "y_pred = percep.forward(torch.tensor(X).type(torch.FloatTensor))\n",
    "y_true_tensor = torch.tensor(y_true).type(torch.long)\n",
    "loss = criterion(y_pred, y_true_tensor)\n",
    "print(\"CrossEntropy-Loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "# PyTorch示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 产生数据\n",
    "from numpy.random import RandomState\n",
    "rng = RandomState(29)\n",
    "\n",
    "def sim_data(batch_size=10):\n",
    "    x = np.arange(0, batch_size).reshape((batch_size, 1))\n",
    "    y = x*2 + 3 + rng.randn(batch_size, 1)*5\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x22726fd3668>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = sim_data()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "ax.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## 简单前馈神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-1.15(Python3.6.12)",
   "language": "python",
   "name": "tensorflow1.15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
